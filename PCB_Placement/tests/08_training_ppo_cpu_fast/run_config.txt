python train.py --policy PPO --target_exploration_steps 1000 --start_timesteps 500 --max_timesteps 30_000 --evaluate_every 1_000_000 --training_pcb ${RL_PCB}/dataset/base/training.pcb --pcb_idx 4 --evaluation_pcb ${RL_PCB}/dataset/base/evaluation.pcb --tensorboard_dir ${TEST_DIR}/work -w 2.0 --hpwl 6.0 -o 2.0 --hyperparameters ${TEST_DIR}/hyperparameters/hp_ppo.json --incremental_replay_buffer double --verbose 1 --runs 2 --experiment training_ppo_cpu_262 --device cpu
